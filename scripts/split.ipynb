{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938610b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting calamancy\n",
      "  Using cached calamanCy-0.2.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: spacy>=3.5.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from calamancy) (3.8.7)\n",
      "Requirement already satisfied: wasabi>=0.9.1 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from calamancy) (1.1.3)\n",
      "Requirement already satisfied: typer>=0.4.2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from calamancy) (0.19.2)\n",
      "Collecting spacy-transformers<=1.3.5,>=1.2.5 (from calamancy)\n",
      "  Using cached spacy_transformers-1.3.5-cp313-cp313-win_amd64.whl\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy-transformers<=1.3.5,>=1.2.5->calamancy) (2.3.3)\n",
      "Collecting transformers<4.37.0,>=3.4.0 (from spacy-transformers<=1.3.5,>=1.2.5->calamancy)\n",
      "  Using cached transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy-transformers<=1.3.5,>=1.2.5->calamancy) (2.8.0+cu129)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy-transformers<=1.3.5,>=1.2.5->calamancy) (2.5.1)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy-transformers<=1.3.5,>=1.2.5->calamancy) (0.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (8.3.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (2.11.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from spacy>=3.5.0->calamancy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.5.0->calamancy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->calamancy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->calamancy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->calamancy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->calamancy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.5.0->calamancy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.5.0->calamancy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.5.0->calamancy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.5.0->calamancy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.5.0->calamancy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.5.0->calamancy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=3.5.0->calamancy) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (0.35.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (2025.9.18)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.37.0,>=3.4.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy)\n",
      "  Using cached tokenizers-0.15.2-cp313-cp313-win_amd64.whl\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers<4.37.0,>=3.4.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (2025.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from typer>=0.4.2->calamancy) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from typer>=0.4.2->calamancy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from typer>=0.4.2->calamancy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.5.0->calamancy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.5.0->calamancy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.5.0->calamancy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.5.0->calamancy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.4.2->calamancy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.4.2->calamancy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.4.2->calamancy) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from torch>=1.8.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from torch>=1.8.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->spacy-transformers<=1.3.5,>=1.2.5->calamancy) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vladimir\\documents\\coders\\calamancy\\.venv\\lib\\site-packages (from jinja2->spacy>=3.5.0->calamancy) (3.0.2)\n",
      "Using cached calamanCy-0.2.2-py3-none-any.whl (9.8 kB)\n",
      "Using cached transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "Installing collected packages: tokenizers, transformers, spacy-transformers, calamancy\n",
      "\n",
      "  Attempting uninstall: tokenizers\n",
      "\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "\n",
      "   ---------------------------------------- 0/4 [tokenizers]\n",
      "   ---------------------------------------- 0/4 [tokenizers]\n",
      "  Attempting uninstall: transformers\n",
      "   ---------------------------------------- 0/4 [tokenizers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "    Found existing installation: transformers 4.45.2\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "    Uninstalling transformers-4.45.2:\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "      Successfully uninstalled transformers-4.45.2\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   ---------- ----------------------------- 1/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [spacy-transformers]\n",
      "   -------------------- ------------------- 2/4 [spacy-transformers]\n",
      "   -------------------- ------------------- 2/4 [spacy-transformers]\n",
      "   -------------------- ------------------- 2/4 [spacy-transformers]\n",
      "   ---------------------------------------- 4/4 [calamancy]\n",
      "\n",
      "Successfully installed calamancy-0.2.2 spacy-transformers-1.3.5 tokenizers-0.15.2 transformers-4.36.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gliner 0.2.8 requires transformers>=4.38.2, but you have transformers 4.36.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install calamancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17134caf-e7b7-4676-8651-1222ce26fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy: 3.8.7\n",
      "Calamancy: 0.2.2\n"
     ]
    }
   ],
   "source": [
    "import spacy, calamancy\n",
    "\n",
    "print(\"spaCy:\", spacy.__version__)\n",
    "print(\"Calamancy:\", calamancy.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7867317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_seed = 42\n",
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97251e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_name = \"batch_1-2\"\n",
    "dataset_file_path = f\"../assets/json_records/{dataset_name}\"\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(dataset_name, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a02944-663f-4c61-808e-1cd04850f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Weird characters scanned. Results saved to weird_chars.json\n"
     ]
    }
   ],
   "source": [
    "import json, unicodedata, collections\n",
    "\n",
    "# Load dataset\n",
    "with open(f\"{dataset_file_path}/records_clean.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Store character info\n",
    "char_stats = collections.Counter()\n",
    "char_examples = {}\n",
    "\n",
    "def analyze_text(text, rec_id):\n",
    "    for ch in text:\n",
    "        if ord(ch) > 127 or ch in [\"\\u200b\", \"\\u00a0\"]:  # non-ASCII, zero-width, NBSP\n",
    "            key = f\"{ch} | U+{ord(ch):04X} | {unicodedata.name(ch, 'UNKNOWN')}\"\n",
    "            char_stats[key] += 1\n",
    "            if key not in char_examples:\n",
    "                # keep first 2 examples only\n",
    "                char_examples[key] = []\n",
    "            if len(char_examples[key]) < 2:\n",
    "                snippet = text[:100].replace(\"\\n\", \" \")\n",
    "                char_examples[key].append({\"record_id\": rec_id, \"sample\": snippet})\n",
    "\n",
    "# Scan all records\n",
    "for rec in data:\n",
    "    text = rec[\"fields\"][\"Text\"]\n",
    "    analyze_text(text, rec.get(\"id\"))\n",
    "\n",
    "# Save summary\n",
    "summary = []\n",
    "for char_key, count in char_stats.most_common():\n",
    "    summary.append({\n",
    "        \"char\": char_key,\n",
    "        \"count\": count,\n",
    "        \"examples\": char_examples.get(char_key, [])\n",
    "    })\n",
    "\n",
    "with open(f\"{dataset_file_path}/weird_chars.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Weird characters scanned. Results saved to weird_chars.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d109aa9-b823-46e0-8c50-924674166fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 2700\n"
     ]
    }
   ],
   "source": [
    "print(\"Total records:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fd5454d6-dd33-4eb1-9d13-a45a7836eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlaps(entities, text):\n",
    "    \"\"\"Detect overlaps in list of (start, end, label) and return span text too.\"\"\"\n",
    "    overlaps = []\n",
    "    # Sort by start index\n",
    "    entities_sorted = sorted(entities, key=lambda x: (x[0], x[1]))\n",
    "    for i in range(len(entities_sorted) - 1):\n",
    "        start1, end1, label1 = entities_sorted[i]\n",
    "        start2, end2, label2 = entities_sorted[i+1]\n",
    "        # If the next entity starts before the current one ends → overlap\n",
    "        if start2 < end1:\n",
    "            overlaps.append({\n",
    "                \"first\": {\n",
    "                    \"start\": start1,\n",
    "                    \"end\": end1,\n",
    "                    \"label\": label1,\n",
    "                    \"text\": text[start1:end1]\n",
    "                },\n",
    "                \"second\": {\n",
    "                    \"start\": start2,\n",
    "                    \"end\": end2,\n",
    "                    \"label\": label2,\n",
    "                    \"text\": text[start2:end2]\n",
    "                }\n",
    "            })\n",
    "    return overlaps\n",
    "\n",
    "# ---------- Helper functions -------------\n",
    "def remove_white_space_from_span(text : str, start : int, end : int):\n",
    "    curr_text_len = len(text)\n",
    "    adjusted = False\n",
    "    # print(text)\n",
    "\n",
    "    text = text.lstrip()\n",
    "    if len(text) < curr_text_len:\n",
    "        end -= curr_text_len - len(text)\n",
    "        curr_text_len = len(text)\n",
    "        adjusted = True\n",
    "\n",
    "    text = text.rstrip()\n",
    "    if len(text) < curr_text_len:\n",
    "        end -= curr_text_len - len(text)\n",
    "        curr_text_len = len(text)\n",
    "        adjusted = True\n",
    "    \n",
    "    if adjusted:\n",
    "        out = {\n",
    "            \"text\": text,\n",
    "            \"start\": start,\n",
    "            \"end\": end\n",
    "        }\n",
    "        display(f\"Cleaned: {out}\")\n",
    "        return out\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d21b07cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Dangadang', 'start': 8, 'end': 17}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'Dangadang', 'start': 8, 'end': 17}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = {\"text\": \"Ayon sa Dangadang (Sandatahang Pakikibaka), pahayagang masa sa rehiyon, sa isyu noong Nobyembre, una'y nagpetisyon ang mga taumbaryo sa meyor na pahintuin ang mga manggugubat (forester) ng BFD na magtanim sa kanilang mga lupaing sinasaka. Nang di ito pinakinggan, pinagbunot ng galit na mga mamamayang Igorot ang nakatanim na mga punong-kahoy.\",\n",
    "\"span_text\": \"Dangadang \",\n",
    "\"start\": 8,\n",
    "\"end\": 18,}\n",
    "\n",
    "remove_white_space_from_span(sample[\"span_text\"], sample[\"start\"], sample[\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stratified_sample, _ = train_test_split(data, test_size=0.999, stratify=data[[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ef881-f270-4690-ba2c-fe89a2d8fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import calamancy\n",
    "import unicodedata\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "# Load calamancy Tagalog model\n",
    "nlp = calamancy.load(\"tl_calamancy_md-0.2.0\")\n",
    "\n",
    "# Load JSON\n",
    "# with open(f\"{dataset_file_path}/records.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# Shuffle dataset for random split\n",
    "# todo: functional stratified sampling\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split ratios\n",
    "train_ratio, dev_ratio, test_ratio = 0.7, 0.1, 0.2\n",
    "n = len(data)\n",
    "n_train = int(n * train_ratio)\n",
    "n_dev = int(n * dev_ratio)\n",
    "\n",
    "train_data = data[:n_train]\n",
    "dev_data = data[n_train:n_train+n_dev]\n",
    "test_data = data[n_train+n_dev:]\n",
    "\n",
    "# Collect misaligned spans for logging\n",
    "misaligned_log = []\n",
    "overlap_log = []\n",
    "dropped_log = []\n",
    "neg_sample_log = []\n",
    "\n",
    "    \n",
    "# ---------- Helper: spaCy format ----------\n",
    "def to_spacy_format(records):\n",
    "    spacy_data = []\n",
    "    for idx, record in enumerate(records):\n",
    "        text = unicodedata.normalize(\"NFC\", record[\"fields\"][\"Text\"])\n",
    "        entities = []\n",
    "        for resp in record.get(\"responses\", {}).get(\"entity_type\", []):\n",
    "            for ent in resp.get(\"value\", []):\n",
    "                entities.append((ent[\"start\"], ent[\"end\"], ent[\"label\"]))\n",
    "\n",
    "        # --- check overlaps here ---\n",
    "        overlaps = find_overlaps(entities, text)\n",
    "        if overlaps:\n",
    "            overlap_log.append({\n",
    "                \"record_id\": record.get(\"id\"),\n",
    "                \"text\": text,\n",
    "                \"overlaps\": overlaps\n",
    "            })\n",
    "            dropped_log.append({\n",
    "                \"record_id\": record.get(\"id\"),\n",
    "                \"text\": text,\n",
    "                \"reason\": \"overlap\",\n",
    "                \"details\": overlaps\n",
    "            })\n",
    "            continue  # still skip the record completely\n",
    "\n",
    "        # --- continue with alignment check ---\n",
    "        aligned_entities = []\n",
    "        for start, end, label in entities:\n",
    "            # doc = nlp.make_doc(text)\n",
    "            # span = doc.char_span(start, end, label=label)\n",
    "            cleaned = remove_white_space_from_span(text[start:end], start, end)\n",
    "\n",
    "            if (cleaned is not None):\n",
    "                # aligned_entities.append((cleaned[\"start\"], cleaned[\"end\"], label))\n",
    "                misaligned_log.append({\n",
    "                    \"record_id\": record.get(\"id\"),\n",
    "                    \"text\": text,\n",
    "                    \"span_text\": text[start:end],\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"label\": label\n",
    "                })\n",
    "                start = cleaned[\"start\"]\n",
    "                end = cleaned[\"end\"]\n",
    "                # span_text = cleaned[\"text\"]\n",
    "                if (start == end):\n",
    "                    # empty span\n",
    "                    dropped_log.append({\n",
    "                        \"record_id\": record.get(\"id\"),\n",
    "                        \"text\": text,\n",
    "                        \"reason\": \"overlap\",\n",
    "                        \"details\": overlaps\n",
    "                    })\n",
    "                    continue\n",
    "            aligned_entities.append((start, end, label))\n",
    "\n",
    "        # --- final decision ---\n",
    "        if not aligned_entities:\n",
    "            #  keep as negative example, but log it\n",
    "            spacy_data.append([text, {\"entities\": []}])\n",
    "            neg_sample_log.append({\n",
    "                \"record_id\": record.get(\"id\"),\n",
    "                \"text\": text,\n",
    "                \"reason\": \"no entities (kept as negative example)\"\n",
    "            }) # NO NEED TO LOG AS DROPPED SINCE THEY ARE NEEDED AS NEGATIVE SAMPLES\n",
    "        else:\n",
    "            spacy_data.append([text, {\"entities\": aligned_entities}])\n",
    "    return spacy_data\n",
    "\n",
    "\n",
    "# ---------- Helper: BIO format ----------\n",
    "def to_bio_format(records):\n",
    "    bio_sents = []\n",
    "    for record in records:\n",
    "        text = unicodedata.normalize(\"NFC\", record[\"fields\"][\"Text\"])\n",
    "        entities = []\n",
    "        for resp in record.get(\"responses\", {}).get(\"entity_type\", []):\n",
    "            for ent in resp.get(\"value\", []):\n",
    "                entities.append((ent[\"start\"], ent[\"end\"], ent[\"label\"]))\n",
    "        \n",
    "        doc = nlp(text)\n",
    "        tags = [\"O\"] * len(doc)\n",
    "\n",
    "        for start, end, label in entities:\n",
    "            for i, token in enumerate(doc):\n",
    "                if token.idx >= start and token.idx < end:\n",
    "                    if token.idx == start:\n",
    "                        tags[i] = f\"B-{label}\"\n",
    "                    else:\n",
    "                        tags[i] = f\"I-{label}\"\n",
    "\n",
    "        sent_tags = [(token.text, tags[i]) for i, token in enumerate(doc)]\n",
    "        bio_sents.append(sent_tags)\n",
    "    return bio_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "17ec3eff-c53f-474f-b601-b902c8d0f287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'US', 'start': 150, 'end': 152}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Dangadang', 'start': 8, 'end': 17}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Demokratikong Republikang Bayan ng Korea', 'start': 556, 'end': 596}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Pilipino', 'start': 141, 'end': 149}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Okt. 20', 'start': 106, 'end': 113}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Sakbayan', 'start': 80, 'end': 88}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Masa', 'start': 97, 'end': 101}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Mindanao', 'start': 66, 'end': 74}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Assemblywoman Manotoc', 'start': 78, 'end': 99}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': '78%', 'start': 30, 'end': 33}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'apartheid', 'start': 481, 'end': 490}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'Enero', 'start': 193, 'end': 198}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'HULYO 1985', 'start': 63, 'end': 73}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'korporasyong transnasyonal', 'start': 36, 'end': 62}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Cleaned: {'text': 'SAMBUTANI', 'start': 54, 'end': 63}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: train/dev/test in both spaCy JSON (/json) and BIO (/bio) formats\n",
      "⚠️ Misaligned spans logged: 15\n",
      "⚠️ Overlapping spans logged: 4\n",
      "❌ Dropped entries logged: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "corpus_path = f\"../assets/corpus/{dataset_name}\"\n",
    "\n",
    "os.makedirs(f\"{corpus_path}/json\", exist_ok=True)\n",
    "os.makedirs(f\"{corpus_path}/bio\", exist_ok=True)\n",
    "\n",
    "# ---------- Save outputs ----------\n",
    "for split_name, split_data in [(\"train\", train_data), (\"dev\", dev_data), (\"test\", test_data)]:\n",
    "    # spaCy JSON → inside /json folder\n",
    "    spacy_data = to_spacy_format(split_data)\n",
    "    with open(f\"{corpus_path}/json/{split_name}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(spacy_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # BIO → inside /bio folder\n",
    "    bio_data = to_bio_format(split_data)\n",
    "    with open(f\"{corpus_path}/bio/{split_name}.bio\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sent in bio_data:\n",
    "            for token, tag in sent:\n",
    "                f.write(f\"{token}\\t{tag}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Save misaligned spans log in root\n",
    "with open(f\"{corpus_path}/misaligned.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(misaligned_log, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Saved: train/dev/test in both spaCy JSON (/json) and BIO (/bio) formats\")\n",
    "print(f\"⚠️ Misaligned spans logged: {len(misaligned_log)}\")\n",
    "\n",
    "with open(f\"{corpus_path}/overlaps.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(overlap_log, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"⚠️ Overlapping spans logged: {len(overlap_log)}\")\n",
    "\n",
    "# ---------- Save dropped log ----------\n",
    "with open(f\"{corpus_path}/dropped.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dropped_log, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"❌ Dropped entries logged: {len(dropped_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "87e64932-8c2f-42d1-998e-d15feb51465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Negative example spans logged: 464\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{corpus_path}/neg_sample.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(neg_sample_log, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"⚠️ Negative example spans logged: {len(neg_sample_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b074410f-6720-4719-aa6f-6ffc541aee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json/train.json: 1888 entries\n",
      "json/dev.json: 270 entries\n",
      "json/test.json: 538 entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def count_json_entries(json_file):\n",
    "    with open(f\"{corpus_path}/{json_file}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"{json_file}: {len(data)} entries\")\n",
    "    return len(data)\n",
    "\n",
    "count_json_entries(\"json/train.json\")\n",
    "count_json_entries(\"json/dev.json\")\n",
    "count_json_entries(\"json/test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce385eb-822c-42a7-8f45-edd1a18f5eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 837\n",
      "Dev size: 119\n",
      "Test size: 238\n",
      "Train ∩ Dev: 0\n",
      "Train ∩ Test: 0\n",
      "Dev ∩ Test: 0\n",
      "Total samples: 1194\n",
      "Unique samples: 1194\n",
      "Duplicates overall: 0\n",
      "✅ Duplicate report saved to split_duplicates.json\n"
     ]
    }
   ],
   "source": [
    "import json, unicodedata\n",
    "\n",
    "# Load helper\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def to_key(record):\n",
    "    # Prefer ID if available\n",
    "    if isinstance(record, dict):\n",
    "        if \"id\" in record:\n",
    "            return str(record[\"id\"])\n",
    "\n",
    "        fields = record.get(\"fields\")\n",
    "        if isinstance(fields, dict):\n",
    "            return unicodedata.normalize(\"NFC\", fields.get(\"Text\", \"\"))\n",
    "        elif isinstance(fields, list):\n",
    "            # If fields is a list, join as string for uniqueness\n",
    "            return unicodedata.normalize(\"NFC\", \" \".join(map(str, fields)))\n",
    "    \n",
    "    # fallback: stringify entire record\n",
    "    return unicodedata.normalize(\"NFC\", str(record))\n",
    "\n",
    "# Load all splits\n",
    "train = load_json(\"json/train.json\")\n",
    "dev   = load_json(\"json/dev.json\")\n",
    "test  = load_json(\"json/test.json\")\n",
    "\n",
    "train_keys = {to_key(r) for r in train}\n",
    "dev_keys   = {to_key(r) for r in dev}\n",
    "test_keys  = {to_key(r) for r in test}\n",
    "\n",
    "# Report sizes\n",
    "print(\"Train size:\", len(train_keys))\n",
    "print(\"Dev size:\", len(dev_keys))\n",
    "print(\"Test size:\", len(test_keys))\n",
    "\n",
    "# Overlaps\n",
    "overlap_train_dev = train_keys & dev_keys\n",
    "overlap_train_test = train_keys & test_keys\n",
    "overlap_dev_test = dev_keys & test_keys\n",
    "\n",
    "print(\"Train ∩ Dev:\", len(overlap_train_dev))\n",
    "print(\"Train ∩ Test:\", len(overlap_train_test))\n",
    "print(\"Dev ∩ Test:\", len(overlap_dev_test))\n",
    "\n",
    "# Global uniqueness\n",
    "all_keys = train_keys | dev_keys | test_keys\n",
    "total = len(train) + len(dev) + len(test)\n",
    "print(\"Total samples:\", total)\n",
    "print(\"Unique samples:\", len(all_keys))\n",
    "print(\"Duplicates overall:\", total - len(all_keys))\n",
    "\n",
    "# Optional: save actual duplicates for inspection\n",
    "duplicates = {\n",
    "    \"train_dev\": list(overlap_train_dev),\n",
    "    \"train_test\": list(overlap_train_test),\n",
    "    \"dev_test\": list(overlap_dev_test),\n",
    "}\n",
    "with open(\"split_duplicates.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(duplicates, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Duplicate report saved to split_duplicates.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e44e7e-eb40-48b7-b11b-246905528c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved spacy/train.spacy\n",
      "Saved spacy/dev.spacy\n",
      "Saved spacy/test.spacy\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "os.makedirs(\"spacy\", exist_ok=True)\n",
    "\n",
    "nlp = calamancy.load(\"tl_calamancy_md-0.2.0\")\n",
    "\n",
    "def convert(json_file, spacy_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    doc_bin = DocBin()\n",
    "    for text, annot in data:\n",
    "        # normalize text to avoid encoding mismatches\n",
    "        text = unicodedata.normalize(\"NFC\", text)\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is None:\n",
    "                print(f\"⚠️ Misaligned span skipped: {text[start:end]}\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "\n",
    "        # filter overlaps and assign\n",
    "        doc.ents = filter_spans(ents)\n",
    "        doc_bin.add(doc)\n",
    "\n",
    "    # save binary .spacy file\n",
    "    doc_bin.to_disk(spacy_file)\n",
    "    print(f\"Saved {spacy_file}\")\n",
    "\n",
    "# Convert splits\n",
    "convert(\"json/train.json\", \"spacy/train.spacy\")\n",
    "convert(\"json/dev.json\", \"spacy/dev.spacy\")\n",
    "convert(\"json/test.json\", \"spacy/test.spacy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
