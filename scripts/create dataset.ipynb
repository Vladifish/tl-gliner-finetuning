{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4616b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import srsly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e610c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where our entity mapping file is\n",
    "entity_map = srsly.read_json(\"../assets/mapped_labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f755bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Person-Individual',\n",
       " 'Person-Collective',\n",
       " 'Organization-Political',\n",
       " 'Organization-Government',\n",
       " 'Organization-Military',\n",
       " 'Organization-Other',\n",
       " 'Location',\n",
       " 'Object',\n",
       " 'Time',\n",
       " 'Event-Local',\n",
       " 'Event-International',\n",
       " 'Production-Media',\n",
       " 'Production-Government',\n",
       " 'Production-Doctrine',\n",
       " 'Numerical Statistics']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all the entities\n",
    "entities = entity_map[\"labels\"]\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1935cbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'O',\n",
       " '1': 'B-Person-Individual',\n",
       " '2': 'I-Person-Individual',\n",
       " '3': 'B-Person-Collective',\n",
       " '4': 'I-Person-Collective',\n",
       " '5': 'B-Organization-Political',\n",
       " '6': 'I-Organization-Political',\n",
       " '7': 'B-Organization-Government',\n",
       " '8': 'I-Organization-Government',\n",
       " '9': 'B-Organization-Military',\n",
       " '10': 'I-Organization-Military',\n",
       " '11': 'B-Organization-Other',\n",
       " '12': 'I-Organization-Other',\n",
       " '13': 'B-Location',\n",
       " '14': 'I-Location',\n",
       " '15': 'B-Object',\n",
       " '16': 'I-Object',\n",
       " '17': 'B-Time',\n",
       " '18': 'I-Time',\n",
       " '19': 'B-Event-Local',\n",
       " '20': 'I-Event-Local',\n",
       " '21': 'B-Event-International',\n",
       " '22': 'I-Event-International',\n",
       " '23': 'B-Production-Media',\n",
       " '24': 'I-Production-Media',\n",
       " '25': 'B-Production-Government',\n",
       " '26': 'I-Production-Government',\n",
       " '27': 'B-Production-Doctrine',\n",
       " '28': 'I-Production-Doctrine',\n",
       " '29': 'B-Numerical Statistics',\n",
       " '30': 'I-Numerical Statistics'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_map[\"iob_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4beef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_entity_to_iob(entity_type : str, inside=False) -> int :\n",
    "    iob_num = 0\n",
    "\n",
    "    # might slow things but adding this for checking\n",
    "    if entity_type in entities:\n",
    "        iob_num = entities.index(entity_type)\n",
    "    else:\n",
    "        print(\"Error entity type not found\")\n",
    "        return 0;\n",
    "\n",
    "    # note: the zeroth index in the array is always mapped to the first index in the map\n",
    "    iob_num = iob_num * 2 + 1\n",
    "\n",
    "    if inside:\n",
    "        return iob_num + 1\n",
    "    else:\n",
    "        return iob_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbee188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_to_hf(raw_spacy_directory, set=[\"train\", \"dev\", \"test\"]):\n",
    "    doc_bin = DocBin().from_disk(f\"{raw_spacy_directory}/{set}.spacy\")\n",
    "    \n",
    "    # The model used to construct the doc object\n",
    "    nlp = spacy.blank(\"tl\")  # or the language your corpus uses\n",
    "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "    texts = []\n",
    "    tokens = []\n",
    "    entities = []\n",
    "    iob_tags = []\n",
    "    ids = []\n",
    "\n",
    "    id_iterator = 0\n",
    "\n",
    "    for doc in docs:\n",
    "        texts.append(doc.text)\n",
    "        token_texts = [t.text for t in doc]\n",
    "        \n",
    "        # We'll follow the I-O-B scheme\n",
    "        token_labels = [\"O\"] * len(doc)\n",
    "        token_tags = [0] * len(doc)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            token_tags[ent.start] = convert_entity_to_iob(ent.label_);\n",
    "            token_labels[ent.start] = \"B-\" + ent.label_\n",
    "            for i in range(ent.start + 1, ent.end):\n",
    "                token_labels[i] = \"I-\" + ent.label_\n",
    "                token_tags[i] = convert_entity_to_iob(ent.label_, inside=True);\n",
    "        \n",
    "        tokens.append(token_texts)\n",
    "        entities.append(token_labels)\n",
    "        iob_tags.append(token_tags)\n",
    "        ids.append(id_iterator)\n",
    "\n",
    "        id_iterator += 1\n",
    "\n",
    "    return Dataset.from_dict({\n",
    "        \"id\": ids,\n",
    "        \"tokens\": tokens,\n",
    "        \"entities\": entities, \n",
    "        \"ner_tags\": iob_tags\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9751bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
      "        num_rows: 1879\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
      "        num_rows: 267\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
      "        num_rows: 533\n",
      "    })\n",
      "})\n",
      "{'id': 0, 'tokens': ['Isang', 'demograpo', 'ng', 'UPPI', 'ang', 'nagsabing', 'mababa', 'ang', 'pagtaya', 'sa', 'rate', 'ng', 'namamatay', 'sa', 'dalawang', 'rehiyon', 'ayon', 'sa', 'ulat', 'ng', 'Area', 'Fertility', 'Survey', '.'], 'entities': ['O', 'O', 'O', 'B-Organization-Other', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Numerical Statistics', 'I-Numerical Statistics', 'O', 'O', 'O', 'O', 'B-Production-Media', 'I-Production-Media', 'I-Production-Media', 'O'], 'ner_tags': [0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 30, 0, 0, 0, 0, 23, 24, 24, 0]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad0765b5a364391a310d51cf48399b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84d61863a9a413d9b134214eebb77a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d674f366ff8046db952f16936a471ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load all three sets\n",
    "\n",
    "corpus_directory = \"../assets/corpus/\"\n",
    "dataset_name = \"batch 1 & 2\"\n",
    "\n",
    "train_dataset = spacy_to_hf(f\"{corpus_directory}/{dataset_name}/raw_spacy\", \"train\")\n",
    "dev_dataset   = spacy_to_hf(f\"{corpus_directory}/{dataset_name}/raw_spacy\", \"dev\")\n",
    "test_dataset  = spacy_to_hf(f\"{corpus_directory}/{dataset_name}/raw_spacy\", \"test\")\n",
    "\n",
    "# 2. Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": dev_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(dataset_dict)\n",
    "print(dataset_dict[\"train\"][0])  # first training sample\n",
    "\n",
    "# 3. Save locally\n",
    "dataset_dict.save_to_disk(f\"{corpus_directory}/{dataset_name}/dataset_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0663ea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
       "        num_rows: 1879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
       "        num_rows: 267\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
       "        num_rows: 533\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_from_disk(f\"{corpus_directory}/{dataset_name}/dataset_full\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab47c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bfc63e2c544811912e2e48f1e7a2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e0addb0b6c4fa6a78bdb931242dade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4451add4d845d9b93270783e22d203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52fdcfbc022457691a9681e25333549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9bbe34a96845a394e135797fe3a1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9505b8c36a27486ea7e3b47b58309200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fa012f2e0b49b48ae0e46be8fa74b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2cd95f7a9446d0bc419e6cb6ce6873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0f13e278794b2796fb676e5d9f8499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2be6eb0659f4171906f05cdd79e16fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acbc3c6c4274c8983cd37a06d254d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e908160af75d4019beb5dc0c6e116cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os;\n",
    "\n",
    "push_to_hub = True\n",
    "\n",
    "owner = \"etdvprg\"\n",
    "hf_dataset_name = \"PHMartialLaw-NER_b12\"\n",
    "\n",
    "if push_to_hub:\n",
    "    api_token = os.getenv(\"HF_TOKEN\")\n",
    "    ds.push_to_hub(f\"{owner}/{hf_dataset_name}\", token=api_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
