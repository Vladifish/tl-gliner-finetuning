{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4616b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import srsly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where our entity mapping file is\n",
    "entity_map = srsly.read_json(\"../assets/mapped_labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Person-Individual',\n",
       " 'Person-Collective',\n",
       " 'Organization-Political',\n",
       " 'Organization-Government',\n",
       " 'Organization-Military',\n",
       " 'Organization-Other',\n",
       " 'Location',\n",
       " 'Object',\n",
       " 'Time',\n",
       " 'Event-Local',\n",
       " 'Event-International',\n",
       " 'Production-Media',\n",
       " 'Production-Government',\n",
       " 'Production-Doctrine',\n",
       " 'Numerical Statistics']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all the entities\n",
    "entities = entity_map[\"labels\"]\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1935cbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'O',\n",
       " '1': 'B-Person-Individual',\n",
       " '2': 'I-Person-Individual',\n",
       " '3': 'B-Person-Collective',\n",
       " '4': 'I-Person-Collective',\n",
       " '5': 'B-Organization-Political',\n",
       " '6': 'I-Organization-Political',\n",
       " '7': 'B-Organization-Government',\n",
       " '8': 'I-Organization-Government',\n",
       " '9': 'B-Organization-Military',\n",
       " '10': 'I-Organization-Military',\n",
       " '11': 'B-Organization-Other',\n",
       " '12': 'I-Organization-Other',\n",
       " '13': 'B-Location',\n",
       " '14': 'I-Location',\n",
       " '15': 'B-Object',\n",
       " '16': 'I-Object',\n",
       " '17': 'B-Time',\n",
       " '18': 'I-Time',\n",
       " '19': 'B-Event-Local',\n",
       " '20': 'I-Event-Local',\n",
       " '21': 'B-Event-International',\n",
       " '22': 'I-Event-International',\n",
       " '23': 'B-Production-Media',\n",
       " '24': 'I-Production-Media',\n",
       " '25': 'B-Production-Government',\n",
       " '26': 'I-Production-Government',\n",
       " '27': 'B-Production-Doctrine',\n",
       " '28': 'I-Production-Doctrine',\n",
       " '29': 'B-Numerical Statistics',\n",
       " '30': 'I-Numerical Statistics'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_map[\"iob_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4beef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_entity_to_iob(entity_type : str, inside=False) -> int :\n",
    "    iob_num = 0\n",
    "\n",
    "    # might slow things but adding this for checking\n",
    "    if entity_type in entities:\n",
    "        iob_num = entities.index(entity_type)\n",
    "    else:\n",
    "        print(\"Error entity type not found\")\n",
    "        return 0;\n",
    "\n",
    "    # note: the zeroth index in the array is always mapped to the first index in the map\n",
    "    iob_num = iob_num * 2 + 1\n",
    "\n",
    "    if inside:\n",
    "        return iob_num + 1\n",
    "    else:\n",
    "        return iob_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcbee188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
      "        num_rows: 1879\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
      "        num_rows: 267\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
      "        num_rows: 533\n",
      "    })\n",
      "})\n",
      "{'id': 0, 'tokens': ['Isang', 'demograpo', 'ng', 'UPPI', 'ang', 'nagsabing', 'mababa', 'ang', 'pagtaya', 'sa', 'rate', 'ng', 'namamatay', 'sa', 'dalawang', 'rehiyon', 'ayon', 'sa', 'ulat', 'ng', 'Area', 'Fertility', 'Survey', '.'], 'entities': ['O', 'O', 'O', 'B-Organization-Other', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Numerical Statistics', 'I-Numerical Statistics', 'O', 'O', 'O', 'O', 'B-Production-Media', 'I-Production-Media', 'I-Production-Media', 'O'], 'ner_tags': [0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 30, 0, 0, 0, 0, 23, 24, 24, 0]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5495fb7da58745058b71f053fab762c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3a76975d084eb9afb33f1b748436f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7a6aa16fdb46f9a0dddd5be076ba66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def spacy_to_hf(corpus_folder, set=[\"train\", \"dev\", \"test\"]):\n",
    "    doc_bin = DocBin().from_disk(f\"../experiments/corpus/{set}.spacy\")\n",
    "    \n",
    "    # The model used to construct the doc object\n",
    "    nlp = spacy.blank(\"en\")  # or the language your corpus uses\n",
    "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "    texts = []\n",
    "    tokens = []\n",
    "    entities = []\n",
    "    iob_tags = []\n",
    "    ids = []\n",
    "\n",
    "    id_iterator = 0\n",
    "\n",
    "    for doc in docs:\n",
    "        texts.append(doc.text)\n",
    "        token_texts = [t.text for t in doc]\n",
    "        \n",
    "        # We'll follow the I-O-B scheme\n",
    "        token_labels = [\"O\"] * len(doc)\n",
    "        token_tags = [0] * len(doc)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            token_tags[ent.start] = convert_entity_to_iob(ent.label_);\n",
    "            token_labels[ent.start] = \"B-\" + ent.label_\n",
    "            for i in range(ent.start + 1, ent.end):\n",
    "                token_labels[i] = \"I-\" + ent.label_\n",
    "                token_tags[i] = convert_entity_to_iob(ent.label_, inside=True);\n",
    "        \n",
    "        tokens.append(token_texts)\n",
    "        entities.append(token_labels)\n",
    "        iob_tags.append(token_tags)\n",
    "        ids.append(id_iterator)\n",
    "\n",
    "        id_iterator += 1\n",
    "\n",
    "    return Dataset.from_dict({\n",
    "        \"id\": ids,\n",
    "        \"tokens\": tokens,\n",
    "        \"entities\": entities, \n",
    "        \"ner_tags\": iob_tags\n",
    "    })\n",
    "\n",
    "# 1. Load all three sets\n",
    "\n",
    "corpus_directory = \"../experiments/corpus/\"\n",
    "dataset_name = \"batch 1\"\n",
    "\n",
    "train_dataset = spacy_to_hf(corpus_directory, \"train\")\n",
    "dev_dataset   = spacy_to_hf(corpus_directory, \"dev\")\n",
    "test_dataset  = spacy_to_hf(corpus_directory, \"test\")\n",
    "\n",
    "# 2. Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": dev_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(dataset_dict)\n",
    "print(dataset_dict[\"train\"][0])  # first training sample\n",
    "\n",
    "# 3. Save locally\n",
    "dataset_dict.save_to_disk(f\"{corpus_directory}/{dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663ea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
       "        num_rows: 1879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
       "        num_rows: 267\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'entities', 'ner_tags'],\n",
       "        num_rows: 533\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_directory = \"../experiments/corpus/\"\n",
    "dataset_name = \"batch_1\"\n",
    "\n",
    "ds = load_from_disk(f\"{corpus_directory}/{dataset_name}\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab47c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea60b4afedc24c428e5cfafe997e271e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da222530a3fc45a3bcd4d6a81142a11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0ea91c8cb94db1919a232781ff1b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cefcc4517a24d1eacae570fe23a6870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5149e75aef46ddb40c0d974bd1cd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5d8f41e87347d9b9f31c046b2b5a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b0d569c073416ca44e61e0d994480c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35d5db7bb07411e96715b33c66f8542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25bc437e62142dcaf51e17d15092d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa39a81f83124fe4a45cd8399080b650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38ba822460d40f2becef1b3744bd47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7571f30497194a80b1655737a883fd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3128df3593d54ad4b3f21f96c02b5a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/555 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os; \n",
    "\n",
    "push_to_hub = True\n",
    "\n",
    "if push_to_hub:\n",
    "    api_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if push_to_hub:\n",
    "    ds.push_to_hub(\"etdvprg/gold-ml-batch1\", token=api_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
